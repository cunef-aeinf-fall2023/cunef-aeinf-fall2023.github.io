<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Tema 4</title>
    <meta charset="utf-8" />
    <meta name="author" content="Roi Naveiro" />
    <script src="libs/header-attrs-2.25/header-attrs.js"></script>
    <link rel="stylesheet" href="ds_slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">






class: center, middle, inverse, title-slide

&lt;div class="title-logo"&gt;&lt;/div&gt;

# Análisis y Explotación de la Información
 
## Tema 4 - Modelización

&lt;br&gt;
&lt;br&gt;
.pull-left[
### Roi Naveiro
]
---
## Modelización

Las herramientas de modelización tienen cuatro objetivos fundamentales:

* **Explorar** los datos: los modelos a veces revelan patrones que no son evidentes en
las visualizaciónes (&gt;3D)

* **Generalizar** hallazgos de una muestra a la población (inferencia)

* Determinar **relaciones causa-efecto** (inferencia causal)


&lt;img src="img/data-science-model.png" width="100%" style="display: block; margin: auto;" /&gt;

---
## Modelización

Los patrones descubiertos por las herramientas de modelización pueden ser:

* Patrones de asociación
* Relaciones causa-efecto

Además, estos patrones pueden:

* Darse únicamente en los datos observados
* Generalizarse a la población 

---
## Modelización

La forma de recolectar los datos afecta al tipo de generalización de las 
conclusiones:

* Si queremos que las conclusiones extraídas a partir de una muestra de datos
sean generalizables a la población, debemos muestrear los sujetos **al azar**.

&lt;img src="img/bdl.png" width="100%" style="display: block; margin: auto;" /&gt;

[Fuente](https://www.huffingtonpost.es/2016/03/28/troleo-en-la-red-para-bautizar-blas-de-lezo-a-un-buque-brita_n_9556114.html)

---
## Modelización

¿Muestrear datos al azar nos garantiza que los patrones detectados sean relaciones 
causa-efecto reales?

---
## Study: Cereal Keeps Girls Slim
 
Se observó que las mujeres que desayunaban tenían un **índice de masa corporal promedio más bajo**, un indicador común de obesidad, que las que no desayunaban. El índice fue aún más bajo para las que **desayunaban cereales**, según los hallazgos del estudio realizado por el Instituto de Investigación Médica de Maryland con fondos de NIH y el fabricante de cereales General Mills.

[...]

Los resultados se obtuvieron de una encuesta de NIH de 2379 mujeres en California, Ohio y Maryland.

[...]

Como parte de la encuesta, se preguntaba a las niñas una vez al año qué habían comido durante los tres días anteriores...

[Fuente](https://www.cbsnews.com/news/study-cereal-keeps-girls-slim/)

---
## Study: Cereal Keeps Girls Slim

Existen tres posibles explicaciones de este hallazgo:

* Comer cereales es la causa de que las mujeres estén delgadas

* Que las mujeres estén delgadas es la causa de que coman cerales

* Existe una tercera variable que es causa de estas dos, **variable de confusión**

Una **variable de confusión** es una variable exógena que es causa tanto a la variable explicativa como a la de respuesta, y que hace que parezca que existe una relación entre ellas.

---
## Study: Cereal Keeps Girls Slim

"Aquellos que desayunan regularmente tienen **más probabilidades de tener un plan de alimentación estructurado** a lo largo del día y, en consecuencia, es menos probable que coman entre comidas y consuman calorías vacías".

---
## Study: Cereal Keeps Girls Slim

¿Por qué se publica esto?

&lt;img src="img/follow-money.jpeg" width="100%" style="display: block; margin: auto;" /&gt;

---
## Estudios científicos

Según el proceso de recolección de los datos, distinguimos estudios:

* **Observacionales**

  * Se recogen datos de forma que no se altera el proceso de generación de los mismos

  * Sirven para determinar **asociación**

* **Experimentales**

  * Se asignan diferentes tratamientos a distintos individuos 

  * Establecer relaciones **causa-efecto**

---
## Estudios científicos

&lt;img src="img/studies.png" width="100%" style="display: block; margin: auto;" /&gt;

---
## Correlación no implica necesariamente causalidad

&lt;img src="img/margarina.png" width="90%" style="display: block; margin: auto;" /&gt;

---
## Modelización

Las herramientas de modelización tienen cuatro objetivos fundamentales:

* **Explorar** los datos: los modelos a veces revelan patrones que no son evidentes en
las visualizaciónes (&gt;3D)

* **Generalizar** hallazgos de una muestra a la población (inferencia)

* Determinar **relaciones causa-efecto** (inferencia causal)

&lt;img src="img/data-science-model.png" width="100%" style="display: block; margin: auto;" /&gt;



---

# Housekeeping

- Midterm 01: will grade within one week!! I'm sure you all did wonderfully!

- Please fill out midterm feedback by end of day today, so I can make changes! https://forms.gle/GfMoYnPNhcY6HVts8

- Project partners

- HW 05

---

class: center, middle

# Inference

---

## Terminology

.vocab[Population]: a group of individuals or objects we are interested in studying

.vocab[Parameter]: a numerical quantity derived from the population
(almost always unknown)

If we had data from every unit in the population, we could just calculate 
population parameters and be done!

--

**Unfortunately, we usually cannot do this. Instead, we work with**

.vocab[Sample]: a subset of our population of interest

.vocab[Statistic]: a numerical quantity derived from a sample

---

## Inference

If the sample is .vocab[representative], then we can use the tools of probability and statistical inference to make .vocab[generalizable] conclusions to the broader population of interest.


&lt;img src="img/soup.png" width="406" height="234" style="display: block; margin: auto;" /&gt;

Similar to tasting a spoonful of soup while cooking to make an inference about the entire pot.

---

## Statistical inference

.vocab[Statistical inference] is the process of using sample data to make 
  conclusions about the underlying population the sample came from.

- .vocab[Estimation]: using the sample to estimate a plausible range of values for the unknown parameter

- .vocab[Testing]: evaluating whether our observed sample provides evidence 
for or against some claim about the population

Today we will focus on **estimation**.

---

class: center, middle

# Estimation

---

## Let's \*virtually\* go to Asheville! 

&lt;img src="img/asheville.jpg" width="450" style="display: block; margin: auto;" /&gt;

**How much should we expect to pay for an Airbnb in Asheville?**


---

## Asheville data

[Inside Airbnb](http://insideairbnb.com/) scraped all Airbnb listings in 
Asheville, NC, that were active on June 25, 2020.

**Population of interest**: listings in the Asheville with at least ten reviews.

**Parameter of interest**: Mean price per guest per night among these 
listings.

.question[
What is the mean price per guest per night among Airbnb rentals in June 2020, 
among Airbnbs with at least ten reviews in Asheville (zip codes 28801 - 28806)?
]

We have data on the price per guest (`ppg`) for a random
sample of 50 Airbnb listings.

---

## Point estimate

A .vocab[point estimate] is a single value computed from the sample data to serve
as the "best guess", or estimate, for the population parameter. 

Our point estimate for the population mean price per guest is the observed sample mean:


```r
abb &lt;- read_csv("data/asheville.csv")
abb %&gt;% 
  summarize(mean_price = mean(ppg))
```

```
## # A tibble: 1 × 1
##   mean_price
##        &lt;dbl&gt;
## 1       76.6
```

---

## Visualizing our sample

&lt;img src="tema4_files/figure-html/unnamed-chunk-10-1.png" width="80%" /&gt;

---

.question[
If you want to catch a fish, do you prefer a spear or a net?
]

.pull-left[
&lt;img src="img/spear.png" width="300" style="display: block; margin: auto;" /&gt;
]
.pull-right[
&lt;img src="img/net.png" width="300" style="display: block; margin: auto;" /&gt;
]

---

.question[
If you want to estimate a population parameter, do you prefer to report a range 
of values the parameter might be in, or a single value?
]

.pull-left[
&lt;img src="img/spear.png" width="300" style="display: block; margin: auto;" /&gt;
]
.pull-right[
&lt;img src="img/net.png" width="300" style="display: block; margin: auto;" /&gt;
]

--

- If we report a point estimate, we probably won’t hit the exact population 
parameter.

- If we report a range of plausible values we have a good shot at capturing 
the parameter.

---

&lt;img src="img/ft-election-poll.png" width="70%" style="display: block; margin: auto;" /&gt;

.footnote[
Source: [Biden vs Trump: who is leading the 2020 US election polls?](https://ig.ft.com/us-election-2020/), 10 Sep 2020.
]


---

class: middle, center

## Confidence intervals

---

## Variability of sample statistics

For a confidence interval for the population mean, we need to come up with a
range of plausible values around our observed sample mean.

- Remember that random samples may differ from each other. If we took another
random sample of 50 Airbnb listings in Asheville, we probably wouldn't get the same mean
price per guest.

--

- There is some .vocab[variability] of the sample mean from these listings.

- To construct a confidence interval, we need to quantify this variability. This
gives us a measurement of how much we expect the sample mean to vary from
sample to sample.

---

.question[
Suppose we split the class in half and ask each student their height. Then, we calculate the mean height of students 
on each side of the classroom. Would you expect these two means to be exactly 
equal, close but not equal, or wildly different?
]

--

&lt;br&gt;&lt;br&gt;

.question[
Suppose you randomly sample 50 students and 5 of them are left handed. If you 
were to take another random sample of 50 students, how many would you expect to 
be left handed? Would you be surprised if only 3 of them were left handed? Would 
you be surprised if 40 of them were left handed?
]

---

## Quantifying the variability

We can quantify the variability of sample statistics using different approaches:

- **Simulation**: via bootstrapping or "resampling" techniques (**today's focus**)

or

- **Theory**: via the Central Limit Theorem (**coming soon!**)

---

class: center, middle

# Bootstrapping

---

## The bootstrap principle

&lt;img src="img/boot.png" style="float:right"&gt;

- The term .vocab[bootstrapping] comes from the phrase "pulling oneself up by one’s 
bootstraps", which is a metaphor for accomplishing an impossible task without 
any outside help.

- In this case the impossible task is estimating a population parameter, and we’ll 
accomplish it using data from only the given sample.

- This notion of saying something about a population parameter using 
only information from an observed sample is the crux of statistical inference;
it is not limited to bootstrapping.

---

## The bootstrap procedure

1. Take a .vocab[bootstrap sample] - a random sample taken **with replacement**
from the original sample, **of the same size** as the original sample.

2. Calculate the bootstrap statistic: the statistic you’re interested in (the 
mean, the median, the correlation, etc.) computed on the bootstrap sample.

3. Repeat steps (1) and (2) many times to create a .vocab[bootstrap distribution] - a distribution of bootstrap statistics.

4. Calculate the bounds of the XX% confidence interval as the middle XX% of the bootstrap distribution.

---

## The original sample

&lt;br&gt;&lt;br&gt;

&lt;img src="tema4_files/figure-html/unnamed-chunk-16-1.png" width="70%" /&gt;

---

## Step-by-step

**Step 1.** Take a .vocab[bootstrap sample]: a random sample taken 
**with replacement** from the original sample, **of the same size** as the 
original sample:



&lt;img src="tema4_files/figure-html/unnamed-chunk-18-1.png" width="70%" /&gt;

---

## Step-by-step

**Step 2.** Calculate the bootstrap statistic (in this case, the sample mean) 
using the bootstrap sample:

&lt;img src="tema4_files/figure-html/unnamed-chunk-19-1.png" width="70%" /&gt;

---

## Step-by-step

**Step 3.** Do steps 1 and 2 over and over again to create a bootstrap 
distribution of sample means:

.pull-left[


]

.pull-right[


]

&lt;img src="tema4_files/figure-html/unnamed-chunk-24-1.png" width="80%" /&gt;
---

## Step-by-step

**Step 3.** In this plot, we've taken 500 bootstrap samples, calculated the
sample mean for each, and plotted them in a histogram:

&lt;img src="tema4_files/figure-html/unnamed-chunk-25-1.png" width="70%" /&gt;

---

**Here we compare the bootstrap distribution of sample means to the distribution
of the original data. What do you notice?**

![](tema4_files/figure-html/unnamed-chunk-26-1.png)&lt;!-- --&gt;

---

## Step-by-step

**Step 4.** Calculate the bounds of the bootstrap interval by using percentiles 
of the bootstrap distribution

&lt;img src="tema4_files/figure-html/unnamed-chunk-27-1.png" width="70%" /&gt;

---

class: center, middle

# Bootstrapping in R

---

## Package `infer`

.pull-left[
![](img/infer.png)
]

.pull-right[
&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
The objective of package `infer` is to perform statistical inference using an 
expressive statistical grammar that coheres with the tidyverse design framework.


```r
library(infer)
```

&lt;br&gt;&lt;br&gt;
[infer.netlify.com](http://infer.netlify.com)
]

---

## Set a seed

Let's set a seed


```r
set.seed(123)
```

Function `set.seed()` is a base R function that allows us to control R's
random number generation. Use this to make your simulation work reproducible.

In other words, it ensures we'll get the same random sample each time we run the code or knit.

---

## Generate bootstrap means


```r
abb %&gt;%
  # specify the variable of interest
* specify(response = ppg)
```

- `specify()` is used to specify which variable in our data frame is the relevant response variable (i.e. the variable we're bootstrapping).

---

## Generate bootstrap means


```r
abb %&gt;%
  # specify the variable of interest
  specify(response = ppg) %&gt;% 
  # generate 15000 bootstrap samples
* generate(reps = 15000, type = "bootstrap")
```

- `generate()` generates the bootstrap samples.

---

## Generate bootstrap means


```r
abb %&gt;%
  # specify the variable of interest
  specify(response = ppg) %&gt;% 
  # generate 15000 bootstrap samples
  generate(reps = 15000, type = "bootstrap") %&gt;% 
  # calculate the statistic of each bootstrap sample
* calculate(stat = "mean")
```

- `calculate()` calculates the sample statistic. In this case, we're using the mean, but we could just as easily calculate, say, bootstrap medians.

---

## Generate bootstrap means




```r
num_reps &lt;- 100
```


```r
# save resulting bootstrap distribution
*boot_dist &lt;- abb %&gt;%
  # specify the variable of interest
  specify(response = ppg) %&gt;% 
  # generate 15000 bootstrap samples
  generate(reps = num_reps, type = "bootstrap") %&gt;% 
  # calculate the statistic of each bootstrap sample
  calculate(stat = "mean")
```

---

## Sample means

How many observations are there in `boot_dist`? What does each observation 
represent?

--


```r
boot_dist
```

```
## Response: ppg (numeric)
## # A tibble: 100 × 2
##    replicate  stat
##        &lt;int&gt; &lt;dbl&gt;
##  1         1  72.5
##  2         2  79.7
##  3         3  63.0
##  4         4  73.1
##  5         5  67.1
##  6         6  78.1
##  7         7  92.1
##  8         8  95.7
##  9         9  88.5
## 10        10  90.8
## # ℹ 90 more rows
```

---

## Visualize the distribution

![](tema4_files/figure-html/unnamed-chunk-37-1.png)&lt;!-- --&gt;

---

## Calculate the confidence interval

A 95% confidence interval is bounded by the middle 95% of the bootstrap 
distribution. To get middle 95%, we want to omit 2.5% on the left and on the right.

--

Use `dplyr` functions:


```r
ci &lt;- boot_dist %&gt;%
  summarise(lower_b = quantile(stat, 0.025), 
            upper_b = quantile(stat, 0.975))
ci
```

```
## # A tibble: 1 × 2
##   lower_b upper_b
##     &lt;dbl&gt;   &lt;dbl&gt;
## 1    60.9    92.1
```

---

## Visualize a confidence interval (Option 1)

Using `geom_vline()` to mark the bounds of the confidence interval



```r
*ggplot(data = boot_dist, mapping = aes(x = stat)) +
  geom_histogram(binwidth = 5, alpha = .5) +
* geom_vline(xintercept = ci$lower_b,
             color = "steelblue", lty = 2, size = 1) + 
* geom_vline(xintercept = ci$upper_b,
             color = "steelblue", lty = 2, size = 1) +
  labs(title = "Bootstrap distribution of mean price-per-guest",
       subtitle = "with 95% confidence interval",
       x = "Means", y = "Count") +
  theme_minimal()
```

---

## Visualize a confidence interval (Option 1)


&lt;img src="tema4_files/figure-html/unnamed-chunk-40-1.png" width="75%" /&gt;

---

## Visualize a confidence interval (Option 2)


```r
*visualize(boot_dist) +
* shade_confidence_interval(endpoints = ci)+
  labs(title = "Bootstrap distribution of mean price-per-guest",
       subtitle = "with 95% confidence interval",
       x = "Means", y = "Count") 
```
---

## Visualize a confidence interval (Option 2)

&lt;img src="tema4_files/figure-html/unnamed-chunk-42-1.png" width="75%" /&gt;
---


## Interpreting a confidence interval

Our 95% confidence interval (CI) is 
(60.9, 92.1).

.question[
Does this mean there is a 95% chance that the true mean price per night in the
population is contained in the interval 
(60.9, 92.1)?
]



---

class: center, middle

.question[
**No!**
]

---

## Interpreting a confidence interval

- The population parameter is either in our interval or it isn't. It can't have a
"95% chance" of being in any specific interval.

--

- The bootstrap distribution captures the variability of the sample mean, but is
based on our original sample. If we started with a different sample, then maybe our estimated 95% confidence 
interval would have also been different.

--

- All we can say is that, if we were to independently take repeated samples from
this population and calculate a 95% CI for the mean in the exact same way, then
we would *expect* 95% of these intervals to contain the population mean.

--

- However, we never know if any particular interval(s) actually do!

---

## Interpretation 

.question[
**We are 95% confident that the mean price per guest per night for Airbnbs in Asheville, NC is between 60.9 and 92.1 dollars. **
]

---
class: center, middle, inverse

# Modelos para Análisis Exploratorio

---
## Modelización

* En lo que resta de curso, introduciremos herramientas básicas de modelización, poniendo
el foco en su uso como **técnicas de exploración** de datos.

* **No** vamos a estudiar cómo usar estas herramientas para generalizar resultados a poblaciones, ni para determinar causalidad.

* No hay nada malo con la exploración, pero nunca debes vender un análisis exploratorio como un análisis confirmatorio porque es **engañoso**.

---
## ¿Qué son los modelos?

* Herramientas que nos permiten extraer patrones de los datos.

* Patrones vs residuos

* Estudiaremos modelos que relacionan un serie de variables (variables predictoras)
coon una variable de interés (variable respuesta)

---
## ¿Qué son los modelos?

* Representamos estas relaciones como **funciones**

* Una función mapea unos inputs a un output

* Esta función tiene input `\(x\)` y output `\(y\)`
$$
y = 3x + 7
$$

---
## ¿Qué son los modelos?


```r
ggplot(mtcars, aes(x=wt, y=mpg)) + geom_point() + theme_minimal() +
  geom_smooth(method="lm", se=FALSE, color='red')
```

![](tema4_files/figure-html/unnamed-chunk-43-1.png)&lt;!-- --&gt;

---
## ¿Qué son los modelos?

Distinguimos elementos importantes

* **Familia de modelos**: definen el patrón que queremos capturar. Por ejemplo:
la familia de modelos lineales que relacionan `\(x\)` con `\(y\)` es:

$$
y = \beta_0 + \beta_1 x
$$

* **Modelo ajustado**: aquel dentro de la familia que mejor reproduce los datos observados

**OJO**: el mejor modelo de la familia no tiene por qué ser la realidad. Los modelos son
simplificaciones de la realidad que nos sirven de algún propósito

---
## ¿Qué son los modelos?

&lt;img src="img/box.jpeg" width="100%" style="display: block; margin: auto;" /&gt;

---
## Vocabulario

* **Variable respuesta**: Variable cuyo comportamiento o variación se está tratando de entender. También llamada variable dependiente. Eje y.

* **Variables explicativas**: otras variables que desea utilizar para explicar la variación en la respuesta. También llamadas variables independientes, covariables, predictores o *features*. Eje x.

* **Valor predicho**: output del modelo para cierto valor de las covariables.

---
## Vocabulario

Discute los elementos anteriores en este ejemplo.


```r
ggplot(mtcars, aes(x=wt, y=mpg)) + geom_point() + theme_minimal() +
  geom_smooth(method="lm", se=FALSE, color='red')
```

![](tema4_files/figure-html/unnamed-chunk-45-1.png)&lt;!-- --&gt;

---
## Ajustando modelos


```r
ggplot(mtcars, aes(x=wt, y=mpg)) + geom_point() + theme_minimal()
```

![](tema4_files/figure-html/unnamed-chunk-46-1.png)&lt;!-- --&gt;

---
## Ajustando modelos

* Los datos anteriores presentan un patrón claro

* Usaremos un modelo para capturar ese patrón y hacerlo explícito

* Un modelo lineal parece razonable `\(y = \beta_0 + \beta_1 x\)`

* Existen infinitos modelos en esta familia

---
## Ajustando modelos


```r
models &lt;- tibble(
  a1 = runif(250, -20, 40),
  a2 = runif(250, -5, 5)
)

ggplot(mtcars, aes(wt, mpg)) + 
  geom_abline(aes(intercept = a1, slope = a2), data = models, alpha = 1/4) +
  geom_point() + theme_minimal()
```

![](tema4_files/figure-html/unnamed-chunk-47-1.png)&lt;!-- --&gt;

---
## Ajustando modelos

* La mayoría de estos modelos son **malos**, no capturan el patrón

* Necesitamos determinar qué modelos son **más cercanos** a los datos

* Una opción, usar el modelo que minimice suma de las distancias verticales de cada
punto a la recta del modelo

---
## Ajustando modelos

![](tema4_files/figure-html/unnamed-chunk-48-1.png)&lt;!-- --&gt;

---
## Regresión lineal

Este modelo se conoce como regresión lineal. Para obtener el valor de los coeficientes 
usando R, hacemos


```r
reg_mod &lt;- lm(mpg ~ wt, data = mtcars)
coef(reg_mod)
```

```
## (Intercept)          wt 
##   37.285126   -5.344472
```

* El objeto `mpg ~ wt` es una fórmula. Equivale a $\text{mpg} = \beta_0 + \beta_1 \cdot \text{wt} $

* Intercept es la estimación del coeficiente `\(\beta_0\)` y el otro número es la estimación de `\(\beta_1\)`

---
## Regresión lineal

La regresión lineal es un modelo estadístico de la relación entre un predictor `\(x\)`
y una variable respuesta cuantitativa `\(y\)` cuando esta relación es lineal con cierto
error `\(\epsilon\)`

$$
y = \beta_0 + \beta_1 x + \epsilon
$$

En este curso no hablaremos mucho del error `\(\epsilon\)` pero recuerda que siempre existe.

---
## Regresión lineal

* Para estimar los valores de `\(\beta_0\)` y `\(\beta_1\)`, usamos los datos.

* Llamamos a las estimaciones `\(b_0\)` y `\(b_1\)` y `\(\hat{y} = b_0 + b_1 x\)`.

* `\(b_0\)` y `\(b_1\)` son aquellos valores que hacen que las distancias verticales vistas anteriormente sean mínimas.

---
## Regresión lineal - Residuos

Los residuos nos dicen cómo de lejos está cada valor predicho de su valore observado

Residuo = Valor observado - valor predicho: `\(y - \hat{y}\)`


---
## Regresión lineal

* La recta de regresión es aquella que minimiza la suma de distancias verticales.

* Esto es equivalente a minimizar la suma de los residuos al cuadrado

`\begin{eqnarray}
&amp;&amp;\sum_{i=1}^n [y_i-\hat{y}_i]^2 = \\
&amp;&amp;\sum_{i=1}^n [y_i-(\beta_0 + \beta_1 x)]^2
\end{eqnarray}`


---
## Visualización de modelos

Podemos visualizar:

* Las predicciones de los modelos

* Los residuos de los modelos

Para esto, utilizamos `modelr` de `tidyverse`

---
## Visualización de modelos

* Primero creamos una red de puntos de la variable predictora


```r
library(modelr)
grid &lt;- mtcars %&gt;% 
  data_grid(wt) 

grid
```

```
## # A tibble: 29 × 1
##       wt
##    &lt;dbl&gt;
##  1  1.51
##  2  1.62
##  3  1.84
##  4  1.94
##  5  2.14
##  6  2.2 
##  7  2.32
##  8  2.46
##  9  2.62
## 10  2.77
## # ℹ 19 more rows
```

---
## Visualización de modelos

* Con el modelo, podemos añadir predicciones


```r
reg_mod &lt;- lm(mpg ~ wt, data = mtcars)

grid &lt;- grid %&gt;% 
  add_predictions(reg_mod)

grid
```

```
## # A tibble: 29 × 2
##       wt  pred
##    &lt;dbl&gt; &lt;dbl&gt;
##  1  1.51  29.2
##  2  1.62  28.7
##  3  1.84  27.5
##  4  1.94  26.9
##  5  2.14  25.8
##  6  2.2   25.5
##  7  2.32  24.9
##  8  2.46  24.1
##  9  2.62  23.3
## 10  2.77  22.5
## # ℹ 19 more rows
```

---
## Visualización de modelos


```r
ggplot(mtcars, aes(wt)) +
  geom_point(aes(y = mpg)) + theme_minimal() +
  geom_line(aes(y = pred), data = grid, colour = "red", size = 1)
```

![](tema4_files/figure-html/unnamed-chunk-52-1.png)&lt;!-- --&gt;


---
## Visualización de modelos

Añadimos residuos usando


```r
reg_mod &lt;- lm(mpg ~ wt, data = mtcars)

mtcars &lt;- mtcars %&gt;% add_residuals(reg_mod)
```

---
## Visualización de modelos


```r
ggplot(mtcars, aes(wt, resid)) + 
  geom_ref_line(h = 0) +
  geom_point() 
```

![](tema4_files/figure-html/unnamed-chunk-54-1.png)&lt;!-- --&gt;

---
## Visualización de modelos

* Las predicciones nos dicen qué patrón hemos capturado

* Los residuos indican qué patrón queda sin capturar


---
## ¿Qué hacer con los modelos?

* **Explicación**: caracterizar la relación entre `\(y\)` y `\(x\)` a través de los parámetros
`\(\beta_0\)` y `\(\beta_1\)`

* **Predicción**: para un nuevo valor de `\(x\)`, obtener su valor `\(y\)`

---
## Interpretación de la regresión lineal

Volvamos a la regresión anterior. La librería `broom` de tidyverse, sirve para 
ordenar los resultados de `lm`. **OJO**: no se carga automáticamente al cargar `tidyverse`.


```r
library(broom)
mod_reg &lt;- lm(mpg ~ wt, data=mtcars)
tidy(mod_reg)
```

```
## # A tibble: 2 × 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)    37.3      1.88      19.9  8.24e-19
## 2 wt             -5.34     0.559     -9.56 1.29e-10
```

---
## Interpretación de la regresión lineal - Pendiente

El modelo de regresión lineal es

$$
\widehat{ \text{mpg} } = \beta_0 + \beta_1 \text{wt}
$$

Aumentemos wt en una unidad

`\begin{eqnarray}
&amp;&amp; \beta_0 + \beta_1 ( \text{wt} + 1) = \\
&amp;&amp; \beta_0 + \beta_1 \text{wt} + \beta_1 = \\
&amp;&amp; \widehat{ \text{mpg} } + \beta_1
\end{eqnarray}`

¿Cómo se interpreta `\(\beta_1\)`?

---
## Interpretación de la regresión lineal - Ordenada en el orign

El modelo de regresión lineal es

$$
\widehat{ \text{mpg} } = \beta_0 + \beta_1 \text{wt}
$$

Sustituímos wt por cero

`\begin{eqnarray}
\widehat{ \text{mpg} } = \beta_0 + \beta_1 \times 0 = \beta_0
\end{eqnarray}`

¿Cómo se interpreta `\(\beta_0\)`?

---
## Interpretación de la Regresión Lineal

Vamos a modelizar cómo afectan los años de experiencia en el salario de un profesor


```r
library(openintro)
data("teacher")
set.seed(1)
grade &lt;- sample(c(rep("elementary", 20), rep("middle", 25), rep("high", 26)))
teacher &lt;- teacher %&gt;%
  mutate(degree = factor(degree, c("MA","BA")),
         grade = grade)
```

---
## Interpretación de la Regresión Lineal

Vamos a modelizar cómo afectan los años de experiencia en el salario de un profesor


```r
ggplot(teacher, aes(x=years, y=base)) + geom_point() + theme_minimal()
```

![](tema4_files/figure-html/unnamed-chunk-57-1.png)&lt;!-- --&gt;

---
## Interpretación de la Regresión Lineal

Ajusta un modelo lineal, obtén los coeficientes e interprétalos.

Determina la predicción del salario de un profesor con 15 años de experiencia.

---
## Interpretación de la Regresión Lineal


```r
ggplot(teacher, aes(x=years, y=base)) + geom_point() +
  geom_smooth(method="lm", color='red', se=FALSE) + theme_minimal()
```

![](tema4_files/figure-html/unnamed-chunk-58-1.png)&lt;!-- --&gt;


---
## Regresión Lineal: Predictores Categóricos

* Hasta ahora hemos considerado la `\(x\)` contínua. ¿Qué sucede si es categórica?

* Imaginemos que la `\(x\)` se refiere a género y toma dos valores: masculino y femenino.

* `\(y = \beta_0 + \beta_1 x\)` no tendría sentido, `\(x\)` no es un número!

* Podemos hacer `\(y = \beta_0 +\beta_1 \text{gen}\_\text{masc}\)`, donde `\(\text{gen}\_\text{masc}\)` toma valor 1 para hombres y cero para mujeres

---
## Regresión Lineal: Predictores Categóricos

* Salario frente a grado. ¿Qué niveles tiene la variable degree?

* Ajustamos un modelo


```r
mod_base_degree &lt;- lm(base ~ degree, data=teacher)
tidy(mod_base_degree)
```

```
## # A tibble: 2 × 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   56610.     1777.    31.8   5.44e-43
## 2 degreeBA       -352.     2398.    -0.147 8.84e- 1
```

---
## Regresión Lineal: Predictores Categóricos

* R ha creado una **variable indicatriz**  degreeBA: si el grado es BA toma valor 1,
sino 0.

* Si la variable tuviese tres niveles A, B y C, R crearía dos variables indicatrices, e.g. para A y B.

* El nivel base es el nivel que toma la variable cuando todas las indicatrices son 0.

* Los coeficientes se interpretan respecto al nivel base.


---
## Regresión Lineal: Predictores Categóricos


```r
mod_base_degree &lt;- lm(base ~ degree, data=teacher)
tidy(mod_base_degree)
```

```
## # A tibble: 2 × 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   56610.     1777.    31.8   5.44e-43
## 2 degreeBA       -352.     2398.    -0.147 8.84e- 1
```
Interpreta cada coeficiente

---
## Regresión Lineal: Visualizamos las predicciones


```r
mod_base_degree &lt;- lm(base ~ degree, data=teacher)

grid &lt;- teacher %&gt;% 
  data_grid(degree) %&gt;% 
  add_predictions(mod_base_degree)
grid
```

```
## # A tibble: 2 × 2
##   degree   pred
##   &lt;fct&gt;   &lt;dbl&gt;
## 1 MA     56610.
## 2 BA     56257.
```

---
## Regresión Lineal: Visualizamos las predicciones


```r
ggplot(teacher, aes(x=degree)) + geom_point(aes(y=base)) + theme_minimal() +
  geom_point(data = grid, aes(y = pred), colour = "red", size = 4)
```

![](tema4_files/figure-html/unnamed-chunk-62-1.png)&lt;!-- --&gt;

---
## Regresión Lineal: Visualizamos las predicciones

Predecimos la media para cada grupo!

---
## Regresión Lineal Múltiple

* En múltiples ocasiones, tenemos más de una variable predictora.

* El modelo lineal más sencillo para este caso, es la **regresión lineal múltiple**

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_p x_p
$$

* El efecto de cada variable se estima independientemente del resto de variables.

---
## Regresión Lineal Múltiple - Interpretación

* ¿Cómo se interpreta `\(\beta_0\)`? 

* ¿Cómo se interpreta `\(\beta_1\)`? 

---
## Regresión Lineal Múltiple 

En R


```r
mod_reg &lt;- lm(base ~ years + degree, data = teacher)
tidy(mod_reg)
```

```
## # A tibble: 3 × 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   44838.    1156.      38.8  4.11e-48
## 2 years           818.      54.0     15.2  1.75e-23
## 3 degreeBA      -2560.    1164.      -2.20 3.12e- 2
```

---
## Regresión Lineal Múltiple 

Visualizamos las predicciones


```r
grid &lt;- teacher %&gt;% 
  data_grid(years, degree) %&gt;% 
  add_predictions(mod_reg)
grid
```

```
## # A tibble: 76 × 3
##    years degree   pred
##    &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;
##  1     0 MA     44838.
##  2     0 BA     42278.
##  3     1 MA     45656.
##  4     1 BA     43096.
##  5     2 MA     46474.
##  6     2 BA     43914.
##  7     3 MA     47292.
##  8     3 BA     44732.
##  9     4 MA     48110.
## 10     4 BA     45550.
## # ℹ 66 more rows
```

---
## Regresión Lineal Múltiple 

Visualizamos las predicciones


```r
ggplot(teacher, aes(years, base, colour = degree)) + 
  geom_point() + 
  geom_line(data = grid, aes(y = pred)) + theme_minimal()
```

![](tema4_files/figure-html/unnamed-chunk-65-1.png)&lt;!-- --&gt;


---
## Bibliografía

Este tema está fundamentalmente basado en  [R for Data Science](https://r4ds.had.co.nz/), Wickham and Grolemund (2016)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightLines": true,
"highlightStyle": "github",
"countIncrementalSlides": false,
"slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<style>
.logo {
  background-image: url(img/logo2.png);
  background-size: contain;
  background-repeat: no-repeat;
  position: absolute;
  top: 1em;
  right: 1em;
  width: 110px;
  height: 128px;
  z-index: 0;
}
</style>

<style>
  .title-logo {
    background-image: url(img/logo2.png);
    background-size: contain;
    background-repeat: no-repeat;
    position: absolute;
    top: 1em;
    left: 20em;
    width: 110px;
    height: 128px;
    z-index: 0;
  }
  </style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // add additional classes to exclude here, e.g.
    // ':not(.inverse)' +
    ':not(.hide-logo)' 

  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
